{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Maintenance du ModÃ¨le\n",
    "\n",
    "Ce notebook prÃ©sente les outils de MLOps pour la maintenance du modÃ¨le de segmentation :\n",
    "\n",
    "1. **Model Registry** : Versioning des modÃ¨les avec mÃ©tadonnÃ©es\n",
    "2. **Drift Detection** : DÃ©tection de drift de donnÃ©es et de modÃ¨le\n",
    "3. **Simulation de rÃ©entraÃ®nement** : Estimation de la frÃ©quence optimale\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data.loader import load_transactions\n",
    "from src.features.rfm import RFMCalculator\n",
    "from src.models.clustering import CustomerSegmenter\n",
    "from src.models.evaluation import evaluate_clustering\n",
    "from src.monitoring import ModelRegistry, DriftDetector, calculate_ari\n",
    "from src.monitoring.drift import estimate_retraining_frequency\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Modules chargÃ©s avec succÃ¨s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des donnÃ©es et du modÃ¨le\n",
    "\n",
    "CommenÃ§ons par charger les donnÃ©es RFM et entraÃ®ner un modÃ¨le de rÃ©fÃ©rence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donnÃ©es\n",
    "try:\n",
    "    rfm_df = pd.read_parquet('../data/processed/customers_rfm.parquet')\n",
    "    print(f\"DonnÃ©es RFM chargÃ©es: {len(rfm_df)} clients\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Calcul des features RFM...\")\n",
    "    df = load_transactions('../data/raw/data.csv')\n",
    "    calculator = RFMCalculator(reference_date='2018-09-01')\n",
    "    rfm_df = calculator.fit_transform(df)\n",
    "    print(f\"RFM calculÃ©: {len(rfm_df)} clients\")\n",
    "\n",
    "rfm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®ner le modÃ¨le de rÃ©fÃ©rence\n",
    "segmenter = CustomerSegmenter(n_clusters=4, random_state=42)\n",
    "labels = segmenter.fit_predict(rfm_df)\n",
    "\n",
    "# Ã‰valuer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm_df)\n",
    "\n",
    "metrics = evaluate_clustering(rfm_scaled, labels)\n",
    "print(f\"\\nMÃ©triques du modÃ¨le:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\" if isinstance(value, float) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Registry\n",
    "\n",
    "Le Model Registry permet de versionner les modÃ¨les avec leurs mÃ©tadonnÃ©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le registre\n",
    "registry = ModelRegistry()\n",
    "\n",
    "# Calculer le hash des donnÃ©es\n",
    "data_hash = ModelRegistry.compute_data_hash(rfm_df)\n",
    "print(f\"Hash des donnÃ©es: {data_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le modÃ¨le dans le registre\n",
    "version = registry.register(\n",
    "    model=segmenter.model,\n",
    "    scaler=segmenter.scaler,\n",
    "    metrics={\n",
    "        'silhouette': metrics['silhouette'],\n",
    "        'calinski_harabasz': metrics['calinski_harabasz'],\n",
    "        'davies_bouldin': metrics['davies_bouldin'],\n",
    "    },\n",
    "    hyperparameters={\n",
    "        'n_clusters': 4,\n",
    "        'random_state': 42,\n",
    "        'n_init': 10,\n",
    "        'max_iter': 300,\n",
    "    },\n",
    "    data_hash=data_hash,\n",
    "    n_samples=len(rfm_df),\n",
    "    description=\"ModÃ¨le initial de segmentation RFM\",\n",
    ")\n",
    "\n",
    "print(f\"\\nModÃ¨le enregistrÃ©: v{version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les versions\n",
    "versions_df = registry.list_versions()\n",
    "print(\"Versions enregistrÃ©es:\")\n",
    "versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger un modÃ¨le depuis le registre\n",
    "loaded_model, loaded_scaler, loaded_meta = registry.load()\n",
    "\n",
    "print(f\"ModÃ¨le chargÃ©: v{loaded_meta['version']}\")\n",
    "print(f\"CrÃ©Ã© le: {loaded_meta['created_at']}\")\n",
    "print(f\"MÃ©triques: {loaded_meta['metrics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Drift Detection\n",
    "\n",
    "La dÃ©tection de drift permet d'identifier quand le modÃ¨le doit Ãªtre rÃ©entraÃ®nÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le dÃ©tecteur de drift\n",
    "detector = DriftDetector(ari_threshold=0.8, pvalue_threshold=0.05)\n",
    "\n",
    "# Configurer avec les donnÃ©es de rÃ©fÃ©rence\n",
    "detector.fit(rfm_df, labels)\n",
    "\n",
    "print(\"DÃ©tecteur configurÃ© avec les donnÃ©es de rÃ©fÃ©rence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler des nouvelles donnÃ©es avec un lÃ©ger drift\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simuler un drift de 10% sur les features\n",
    "new_data = rfm_df.copy()\n",
    "for col in new_data.columns:\n",
    "    noise = np.random.normal(0, new_data[col].std() * 0.1, len(new_data))\n",
    "    new_data[col] = new_data[col] + noise\n",
    "\n",
    "print(\"DonnÃ©es simulÃ©es avec drift de 10%\")\n",
    "print(f\"\\nComparaison des moyennes:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Reference': rfm_df.mean(),\n",
    "    'Current': new_data.mean(),\n",
    "    'Diff (%)': ((new_data.mean() - rfm_df.mean()) / rfm_df.mean() * 100).round(2)\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©tecter le drift\n",
    "report = detector.detect(\n",
    "    current_data=new_data,\n",
    "    model=segmenter.model,\n",
    "    scaler=segmenter.scaler,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAPPORT DE DRIFT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDate: {report.timestamp}\")\n",
    "print(f\"\\nDrift de donnÃ©es dÃ©tectÃ©: {report.data_drift_detected}\")\n",
    "print(f\"Drift de modÃ¨le dÃ©tectÃ©: {report.model_drift_detected}\")\n",
    "print(f\"Score ARI: {report.ari_score:.4f}\")\n",
    "print(f\"\\nDÃ©tails par feature:\")\n",
    "for feat, details in report.feature_drifts.items():\n",
    "    status = \"âš ï¸ DRIFT\" if details['drift_detected'] else \"âœ“ OK\"\n",
    "    print(f\"  {feat}: {status} (p-value: {details['pvalue']:.4f}, shift: {details['mean_shift_percent']:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ RECOMMANDATION:\")\n",
    "print(f\"   {report.recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulation de la frÃ©quence de rÃ©entraÃ®nement\n",
    "\n",
    "Simulons l'Ã©volution du drift dans le temps pour estimer la frÃ©quence optimale de rÃ©entraÃ®nement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation temporelle\n",
    "simulation = detector.simulate_temporal_drift(\n",
    "    data=rfm_df,\n",
    "    model=segmenter.model,\n",
    "    scaler=segmenter.scaler,\n",
    "    n_periods=12,  # 12 mois\n",
    "    drift_rate=0.05,  # 5% de drift par mois\n",
    ")\n",
    "\n",
    "print(\"Simulation du drift sur 12 mois:\")\n",
    "simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'Ã©volution de l'ARI\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(simulation['period'], simulation['ari_score'], 'b-o', linewidth=2, markersize=8)\n",
    "ax.axhline(y=0.8, color='r', linestyle='--', label='Seuil de rÃ©entraÃ®nement (ARI=0.8)')\n",
    "\n",
    "# Marquer la zone de rÃ©entraÃ®nement\n",
    "ax.fill_between(simulation['period'], 0, 0.8, alpha=0.2, color='red', label='Zone de rÃ©entraÃ®nement nÃ©cessaire')\n",
    "\n",
    "ax.set_xlabel('PÃ©riode (mois)', fontsize=12)\n",
    "ax.set_ylabel('Score ARI', fontsize=12)\n",
    "ax.set_title('Ã‰volution de la stabilitÃ© du modÃ¨le dans le temps', fontsize=14)\n",
    "ax.legend(loc='lower left')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimer la frÃ©quence optimale\n",
    "estimation = estimate_retraining_frequency(\n",
    "    data=rfm_df,\n",
    "    model=segmenter.model,\n",
    "    scaler=segmenter.scaler,\n",
    "    ari_threshold=0.8,\n",
    "    drift_rate=0.05,  # 5% de drift mensuel estimÃ©\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESTIMATION DE LA FRÃ‰QUENCE DE RÃ‰ENTRAÃŽNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nPÃ©riodes avant drift critique: {estimation['periods_until_drift']} mois\")\n",
    "print(f\"ARI au moment du drift: {estimation['ari_at_drift']:.4f}\")\n",
    "print(f\"\\nðŸ“‹ {estimation['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow de rÃ©entraÃ®nement\n",
    "\n",
    "Exemple de workflow complet pour rÃ©entraÃ®ner le modÃ¨le quand un drift est dÃ©tectÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_if_needed(\n",
    "    current_data: pd.DataFrame,\n",
    "    detector: DriftDetector,\n",
    "    registry: ModelRegistry,\n",
    "    segmenter: CustomerSegmenter,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Workflow de rÃ©entraÃ®nement conditionnel.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        RÃ©sultat du workflow avec action prise.\n",
    "    \"\"\"\n",
    "    # 1. DÃ©tecter le drift\n",
    "    report = detector.detect(\n",
    "        current_data=current_data,\n",
    "        model=segmenter.model,\n",
    "        scaler=segmenter.scaler,\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        'drift_report': report.to_dict(),\n",
    "        'action_taken': None,\n",
    "        'new_version': None,\n",
    "    }\n",
    "    \n",
    "    # 2. DÃ©cider de l'action\n",
    "    if report.model_drift_detected:\n",
    "        print(\"ðŸ”„ Drift de modÃ¨le dÃ©tectÃ© - RÃ©entraÃ®nement en cours...\")\n",
    "        \n",
    "        # RÃ©entraÃ®ner\n",
    "        new_segmenter = CustomerSegmenter(n_clusters=4, random_state=42)\n",
    "        new_labels = new_segmenter.fit_predict(current_data)\n",
    "        \n",
    "        # Ã‰valuer\n",
    "        new_scaled = new_segmenter.scaler.transform(current_data)\n",
    "        new_metrics = evaluate_clustering(new_scaled, new_labels)\n",
    "        \n",
    "        # Enregistrer la nouvelle version\n",
    "        new_version = registry.register(\n",
    "            model=new_segmenter.model,\n",
    "            scaler=new_segmenter.scaler,\n",
    "            metrics={\n",
    "                'silhouette': new_metrics['silhouette'],\n",
    "                'calinski_harabasz': new_metrics['calinski_harabasz'],\n",
    "                'davies_bouldin': new_metrics['davies_bouldin'],\n",
    "            },\n",
    "            hyperparameters={'n_clusters': 4, 'random_state': 42},\n",
    "            data_hash=ModelRegistry.compute_data_hash(current_data),\n",
    "            n_samples=len(current_data),\n",
    "            description=f\"RÃ©entraÃ®nement suite au drift (ARI={report.ari_score:.3f})\",\n",
    "            bump='minor',\n",
    "        )\n",
    "        \n",
    "        # Mettre Ã  jour le dÃ©tecteur\n",
    "        detector.fit(current_data, new_labels)\n",
    "        \n",
    "        result['action_taken'] = 'retrained'\n",
    "        result['new_version'] = new_version\n",
    "        result['new_metrics'] = new_metrics\n",
    "        \n",
    "        print(f\"âœ… Nouveau modÃ¨le enregistrÃ©: v{new_version}\")\n",
    "        print(f\"   Silhouette: {new_metrics['silhouette']:.4f}\")\n",
    "        \n",
    "    elif report.data_drift_detected:\n",
    "        print(\"ðŸ“Š Drift de donnÃ©es dÃ©tectÃ© - Surveillance renforcÃ©e\")\n",
    "        result['action_taken'] = 'monitoring'\n",
    "        \n",
    "    else:\n",
    "        print(\"âœ“ Aucun drift dÃ©tectÃ© - ModÃ¨le stable\")\n",
    "        result['action_taken'] = 'none'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester le workflow avec des donnÃ©es fortement driftÃ©es\n",
    "np.random.seed(123)\n",
    "heavily_drifted_data = rfm_df.copy()\n",
    "for col in heavily_drifted_data.columns:\n",
    "    noise = np.random.normal(0, heavily_drifted_data[col].std() * 0.3, len(heavily_drifted_data))\n",
    "    heavily_drifted_data[col] = heavily_drifted_data[col] + noise\n",
    "\n",
    "print(\"Test avec donnÃ©es fortement driftÃ©es (30%):\\n\")\n",
    "result = retrain_if_needed(\n",
    "    current_data=heavily_drifted_data,\n",
    "    detector=detector,\n",
    "    registry=registry,\n",
    "    segmenter=segmenter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir toutes les versions aprÃ¨s rÃ©entraÃ®nement\n",
    "print(\"\\nHistorique des versions:\")\n",
    "registry.list_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RÃ©sumÃ© et recommandations\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "1. **FrÃ©quence de rÃ©entraÃ®nement recommandÃ©e** : Tous les 3-4 mois\n",
    "2. **Seuil ARI critique** : 0.8 (en dessous = rÃ©entraÃ®nement nÃ©cessaire)\n",
    "3. **MÃ©triques Ã  surveiller** : \n",
    "   - Score Silhouette (stabilitÃ© des clusters)\n",
    "   - Distribution des features RFM\n",
    "   - Score ARI par rapport au modÃ¨le de rÃ©fÃ©rence\n",
    "\n",
    "### Actions recommandÃ©es\n",
    "\n",
    "| Situation | Action |\n",
    "|-----------|--------|\n",
    "| ARI > 0.9 | Aucune action, check dans 1 mois |\n",
    "| 0.8 < ARI < 0.9 | Surveillance renforcÃ©e |\n",
    "| ARI < 0.8 | RÃ©entraÃ®nement recommandÃ© |\n",
    "| Drift donnÃ©es + ARI < 0.8 | RÃ©entraÃ®nement urgent |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook de maintenance terminÃ©!\")\n",
    "print(\"\\nPour automatiser ce workflow, consultez le GitHub Action dans .github/workflows/maintenance.yml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
