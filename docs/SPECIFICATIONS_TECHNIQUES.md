# Sp√©cifications Techniques ‚Äî Projet Olist Customer Segmentation

> **Document cr√©√© le :** 2026-01-21
> **Auteur :** Thomas Mebarki
> **Version :** 1.0
> **Statut :** Draft pour refactoring portfolio

---

## Table des Mati√®res

1. [Vue d'ensemble](#1-vue-densemble)
2. [Contexte m√©tier](#2-contexte-m√©tier)
3. [Architecture des donn√©es](#3-architecture-des-donn√©es)
4. [Logique m√©tier ‚Äî Segmentation RFM](#4-logique-m√©tier--segmentation-rfm)
5. [Mod√®les de Machine Learning](#5-mod√®les-de-machine-learning)
6. [Stack technique](#6-stack-technique)
7. [Structure cible du projet](#7-structure-cible-du-projet)
8. [Refactoring n√©cessaire](#8-refactoring-n√©cessaire)
9. [Crit√®res de qualit√©](#9-crit√®res-de-qualit√©)
10. [Roadmap](#10-roadmap)

---

## 1. Vue d'ensemble

### 1.1 Objectif du projet

Segmenter les clients d'**Olist**, une plateforme e-commerce br√©silienne, afin de :
- Identifier les profils clients (VIP, fid√®les, √† risque, dormants)
- Permettre des actions marketing cibl√©es
- Proposer un contrat de maintenance pour la mise √† jour du mod√®le

### 1.2 Objectif portfolio

Transformer ce projet acad√©mique en **projet portfolio professionnel** d√©montrant :
- Ma√Ætrise du Machine Learning non supervis√©
- Comp√©tences en clean code et architecture
- Capacit√© √† produire un livrable industrialisable

---

## 2. Contexte m√©tier

### 2.1 Olist en bref

| Attribut | Valeur |
|----------|--------|
| **Secteur** | E-commerce / Marketplace |
| **Pays** | Br√©sil |
| **Mod√®le** | B2B2C (vendeurs ‚Üí Olist ‚Üí clients) |
| **Volume** | ~100,000 commandes (dataset) |
| **P√©riode** | Sept 2016 ‚Äî Sept 2018 |

### 2.2 Probl√©matique m√©tier

> *"Comment segmenter efficacement nos clients pour optimiser nos campagnes marketing ?"*

**Contraintes :**
- 97% des clients n'ont qu'une seule commande
- Donn√©es limit√©es (pas de donn√©es d√©mographiques)
- Besoin d'une segmentation simple et actionnable

### 2.3 Parties prenantes

| R√¥le | Besoin |
|------|--------|
| **√âquipe Marketing** | Segments clairs pour campagnes cibl√©es |
| **Direction** | ROI des actions marketing |
| **Data Team** | Mod√®le maintenable et reproductible |

---

## 3. Architecture des donn√©es

### 3.1 Sources de donn√©es

```
data/
‚îú‚îÄ‚îÄ data.csv           # Transactions brutes (100k lignes)
‚îú‚îÄ‚îÄ data_2.csv         # Transactions + review_score (95k lignes)
‚îî‚îÄ‚îÄ data_RFM.csv       # Features RFM pr√©-calcul√©es (95k lignes)
```

### 3.2 Sch√©ma des donn√©es brutes (`data.csv`)

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `customer_id` | string | ID unique de la transaction client | `9ef432eb6251...` |
| `customer_unique_id` | string | ID unique du client | `7c396fd4830f...` |
| `order_id` | string | ID de la commande | `e481f51cbdc5...` |
| `price` | float | Montant de la commande | 29.99 |
| `order_purchase_timestamp` | datetime | Date d'achat | `2017-10-02 10:56:33` |

### 3.3 Sch√©ma RFM (`data_RFM.csv`)

| Colonne | Type | Description | Calcul |
|---------|------|-------------|--------|
| `customer_unique_id` | string | ID client (cl√©) | ‚Äî |
| `frequency` | int | Nombre de commandes | `COUNT(order_id)` |
| `recency` | int | Jours depuis derni√®re commande | `MAX_DATE - MAX(order_date)` |
| `amount_spent` | float | Montant total d√©pens√© | `SUM(price)` |

### 3.4 Statistiques cl√©s

| M√©trique | Valeur |
|----------|--------|
| **Clients uniques** | 95,420 |
| **Clients multi-commandes** | 2,913 (3%) |
| **P√©riode couverte** | 728 jours |
| **Montant moyen** | 130.25 BRL |
| **Fr√©quence moyenne** | 1.03 commandes |

---

## 4. Logique m√©tier ‚Äî Segmentation RFM

### 4.1 Principe RFM

Le mod√®le **RFM** (Recency, Frequency, Monetary) est une technique de segmentation client bas√©e sur le comportement d'achat :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SEGMENTATION RFM                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RECENCY    ‚îÇ  FREQUENCY  ‚îÇ  MONETARY (Amount Spent)        ‚îÇ
‚îÇ  (R)        ‚îÇ  (F)        ‚îÇ  (M)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Quand ?    ‚îÇ  Combien    ‚îÇ  Combien d√©pens√© ?              ‚îÇ
‚îÇ  Dernier    ‚îÇ  de fois ?  ‚îÇ                                 ‚îÇ
‚îÇ  achat      ‚îÇ             ‚îÇ                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 4.2 Calcul des features

```python
# Recency : jours depuis le dernier achat
recency = (date_reference - date_dernier_achat).days

# Frequency : nombre total de commandes
frequency = df.groupby('customer_unique_id')['order_id'].count()

# Monetary : montant total d√©pens√©
amount_spent = df.groupby('customer_unique_id')['price'].sum()
```

### 4.3 Segments identifi√©s

| Cluster | Nom sugg√©r√© | Profil | Taille | Action marketing |
|---------|-------------|--------|--------|------------------|
| **0** | R√©cents | R‚Üì F‚Üì M‚Üì | 54% | Fid√©lisation |
| **1** | Fid√®les | R~ F‚Üë M‚Üë | 3% | Programme VIP |
| **2** | Dormants | R‚Üë F‚Üì M‚Üì | 40% | R√©activation |
| **3** | VIP | R~ F‚Üì M‚Üë‚Üë | 3% | R√©tention premium |

---

## 5. Mod√®les de Machine Learning

### 5.1 Comparatif des mod√®les test√©s

| Mod√®le | Silhouette Score | Calinski-Harabasz | Verdict |
|--------|------------------|-------------------|---------|
| **KMeans (k=4)** | **0.677** | **101,980** | ‚úÖ Retenu |
| DBSCAN | 0.459 | 1,128 | ‚ùå Trop de bruit |
| Agglomerative (k=4) | 0.418 | ‚Äî | ‚ùå Moins performant |

### 5.2 Configuration du mod√®le retenu

```python
# Mod√®le final
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Preprocessing
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X[['recency', 'frequency', 'amount_spent']])

# Clustering
model = KMeans(
    n_clusters=4,
    random_state=42,
    n_init=10,
    max_iter=300
)
clusters = model.fit_predict(X_scaled)
```

### 5.3 Validation du mod√®le

**M√©triques utilis√©es :**
- **Silhouette Score** : Mesure la coh√©sion intra-cluster et s√©paration inter-cluster
- **Calinski-Harabasz Index** : Ratio variance inter/intra cluster
- **Elbow Method** : D√©termination du nombre optimal de clusters

### 5.4 Maintenance du mod√®le

**Analyse de stabilit√© temporelle (ARI Score) :**

| Intervalle | ARI Score | Recommandation |
|------------|-----------|----------------|
| 1-10 semaines | > 0.7 | ‚úÖ Stable |
| 10-20 semaines | 0.4-0.7 | ‚ö†Ô∏è Surveillance |
| > 20 semaines | < 0.4 | üîÑ R√©entra√Ænement |

**Fr√©quence de mise √† jour recommand√©e : 3 mois**

---

## 6. Stack technique

### 6.1 D√©pendances Python

```txt
# Core
pandas>=1.5.0
numpy>=1.23.0

# Machine Learning
scikit-learn>=1.2.0

# Visualization
matplotlib>=3.6.0
seaborn>=0.12.0
plotly>=5.11.0

# Clustering visualization
yellowbrick>=1.5

# Hierarchical clustering
scipy>=1.9.0

# Development
jupyter>=1.0.0
ipykernel>=6.0.0
```

### 6.2 Version Python

```
Python 3.10+
```

### 6.3 Outils de qualit√© (√† ajouter)

```txt
# Linting & Formatting
black>=23.0.0
isort>=5.12.0
flake8>=6.0.0

# Type checking
mypy>=1.0.0

# Testing
pytest>=7.0.0
pytest-cov>=4.0.0
```

---

## 7. Structure cible du projet

### 7.1 Arborescence propos√©e

```
olist-customer-segmentation/
‚îÇ
‚îú‚îÄ‚îÄ README.md                    # Documentation principale (portfolio)
‚îú‚îÄ‚îÄ LICENSE                      # MIT License
‚îú‚îÄ‚îÄ pyproject.toml              # Configuration projet & d√©pendances
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances (pip)
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Donn√©es brutes (gitignore)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_2.csv
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Donn√©es transform√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_rfm.csv
‚îÇ   ‚îî‚îÄ‚îÄ README.md               # Description des donn√©es
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py           # Chargement des donn√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py     # Preprocessing & feature engineering
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rfm_calculator.py   # Calcul des features RFM
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clustering.py       # Mod√®les de clustering
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py       # M√©triques d'√©valuation
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plots.py            # Fonctions de visualisation
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ config.py           # Configuration globale
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploration.ipynb    # EDA propre et comment√©
‚îÇ   ‚îú‚îÄ‚îÄ 02_modeling.ipynb       # Entra√Ænement et comparaison
‚îÇ   ‚îî‚îÄ‚îÄ 03_results.ipynb        # R√©sultats et visualisations finales
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_rfm.py
‚îÇ   ‚îî‚îÄ‚îÄ test_clustering.py
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ SPECIFICATIONS_TECHNIQUES.md
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îÇ       ‚îî‚îÄ‚îÄ segments_radar.png
‚îÇ
‚îî‚îÄ‚îÄ .github/
    ‚îî‚îÄ‚îÄ workflows/
        ‚îî‚îÄ‚îÄ ci.yml              # GitHub Actions CI/CD
```

### 7.2 Modules principaux

| Module | Responsabilit√© |
|--------|----------------|
| `data.loader` | Chargement et validation des donn√©es |
| `data.preprocessor` | Nettoyage, transformation |
| `features.rfm_calculator` | Calcul des features RFM |
| `models.clustering` | Entra√Ænement des mod√®les |
| `models.evaluation` | M√©triques et validation |
| `visualization.plots` | Graphiques standardis√©s |

---

## 8. Refactoring n√©cessaire

### 8.1 Code √† extraire en fonctions

```python
# Exemple : rfm_calculator.py

def calculate_rfm(
    df: pd.DataFrame,
    customer_col: str = 'customer_unique_id',
    date_col: str = 'order_purchase_timestamp',
    amount_col: str = 'price',
    reference_date: Optional[datetime] = None
) -> pd.DataFrame:
    """
    Calculate RFM features for customer segmentation.

    Parameters
    ----------
    df : pd.DataFrame
        Transaction data with customer, date, and amount columns.
    customer_col : str
        Name of the customer identifier column.
    date_col : str
        Name of the transaction date column.
    amount_col : str
        Name of the transaction amount column.
    reference_date : datetime, optional
        Reference date for recency calculation. Defaults to max date in data.

    Returns
    -------
    pd.DataFrame
        DataFrame with customer_id, recency, frequency, and monetary columns.

    Examples
    --------
    >>> rfm = calculate_rfm(transactions, reference_date=datetime(2018, 9, 1))
    >>> rfm.head()
    """
    pass
```

### 8.2 Patterns √† appliquer

| Pattern | Application |
|---------|-------------|
| **Single Responsibility** | Une fonction = une t√¢che |
| **DRY** | √âliminer la duplication de code |
| **Type Hints** | Typage explicite des fonctions |
| **Docstrings** | Documentation Google/NumPy style |
| **Constants** | Configuration dans fichier d√©di√© |

### 8.3 Probl√®mes √† corriger

| Probl√®me | Fichier | Action |
|----------|---------|--------|
| Cellules vides | `notebook_essais` | Supprimer |
| IndexError | `notebook_essais:cell-52` | Corriger la fonction |
| ValueError | `notebook_essais:cell-110` | Corriger les dimensions |
| Code dupliqu√© | Tous | Factoriser en fonctions |
| Warnings ignor√©s | Tous | Traiter les warnings |

---

## 9. Crit√®res de qualit√©

### 9.1 Checklist Clean Code

- [ ] Noms de variables explicites (`customer_rfm` vs `data`)
- [ ] Fonctions < 20 lignes
- [ ] Une fonction = un seul niveau d'abstraction
- [ ] Type hints sur toutes les fonctions publiques
- [ ] Docstrings format NumPy/Google
- [ ] Pas de magic numbers (utiliser des constantes)
- [ ] Gestion des erreurs appropri√©e
- [ ] Pas de code comment√©

### 9.2 Checklist Tests

- [ ] Coverage > 80% sur `src/`
- [ ] Tests unitaires pour chaque fonction
- [ ] Tests d'int√©gration pour le pipeline
- [ ] Tests de validation des donn√©es

### 9.3 Checklist Documentation

- [ ] README avec badges, screenshots, instructions
- [ ] Docstrings compl√®tes
- [ ] Architecture document√©e
- [ ] Guide de contribution

### 9.4 Checklist CI/CD

- [ ] GitHub Actions : lint + tests
- [ ] Pre-commit hooks
- [ ] Badge de coverage

---

## 10. Roadmap

### Phase 1 : Audit ‚úÖ
- [x] Analyse des notebooks existants
- [x] Identification des d√©pendances
- [x] Documentation de la logique m√©tier
- [x] Cr√©ation des sp√©cifications techniques

### Phase 2 : Architecture
- [ ] Cr√©ation de la structure de dossiers
- [ ] Setup du projet (pyproject.toml)
- [ ] Configuration des outils de qualit√©

### Phase 3 : Refactoring
- [ ] Extraction du code en modules Python
- [ ] Ajout des type hints et docstrings
- [ ] Cr√©ation des notebooks propres

### Phase 4 : Tests
- [ ] Tests unitaires
- [ ] Tests d'int√©gration
- [ ] Setup CI/CD

### Phase 5 : Documentation
- [ ] README portfolio-ready
- [ ] Documentation technique
- [ ] Visualisations finales

### Phase 6 : Polish
- [ ] Optimisation des visualisations
- [ ] Notebook de d√©monstration
- [ ] (Optionnel) Dashboard Streamlit

---

## Annexes

### A. Glossaire

| Terme | D√©finition |
|-------|------------|
| **RFM** | Recency, Frequency, Monetary ‚Äî m√©thode de segmentation |
| **Silhouette Score** | M√©trique de qualit√© de clustering [-1, 1] |
| **ARI** | Adjusted Rand Index ‚Äî mesure de similarit√© entre clusterings |
| **Elbow Method** | Technique pour d√©terminer le nombre optimal de clusters |

### B. R√©f√©rences

- [Olist Dataset (Kaggle)](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- [Scikit-learn Clustering Documentation](https://scikit-learn.org/stable/modules/clustering.html)
- [RFM Analysis Wikipedia](https://en.wikipedia.org/wiki/RFM_(market_research))

---

*Document g√©n√©r√© par Mary ‚Äî Business Analyst Agent (BMad Method)*
